{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25607,
     "status": "ok",
     "timestamp": 1638721953653,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "wj-cKjjJ87PL",
    "outputId": "a3747918-2274-40b3-e3f3-b8b8bed37037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1638721956924,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "RCxh78ri89Xp",
    "outputId": "1c605623-9f11-45f3-e505-a74a8f3245fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Computer Vision Project/CTC_OMR\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/MyDrive/Computer Vision Project/CTC_OMR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1638709833118,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "GD993Yux_Ehu",
    "outputId": "844ca2dd-bfd0-4c88-d254-25d2e6b21b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mData\u001b[0m/  Sample_code.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4028,
     "status": "ok",
     "timestamp": 1638721963680,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "x_mQwF7I1jAj",
    "outputId": "3993822d-4851-4618-bb31-14e0ee04c793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1638721968392,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "WRocKb761wPv"
   },
   "outputs": [],
   "source": [
    "def word_separator():\n",
    "    return '\\t'\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    return (255. - image)/255.\n",
    "\n",
    "\n",
    "def resize(image, height):\n",
    "    width = int(float(height * image.shape[1]) / image.shape[0])\n",
    "    sample_img = cv2.resize(image, (width, height))\n",
    "    return sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uJV4iauTluwy"
   },
   "outputs": [],
   "source": [
    "def convert_inputs_to_ctc_format(target_text):\n",
    "    SPACE_TOKEN = '-'\n",
    "    SPACE_INDEX = 4\n",
    "    FIRST_INDEX = 0\n",
    "\n",
    "    original = ' '.join(target_text.strip().lower().split(' ')).replace('.', '').replace('?', '').replace(',', '').replace(\"'\", '').replace('!', '').replace('-', '')\n",
    "    print(original)\n",
    "    targets = original.replace(' ', '  ')\n",
    "    targets = targets.split(' ')\n",
    "\n",
    "    # Adding blank label\n",
    "    targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])\n",
    "\n",
    "    # Transform char into index\n",
    "    targets = np.asarray([SPACE_INDEX if x == SPACE_TOKEN else ord(x) - FIRST_INDEX\n",
    "                          for x in targets])\n",
    "\n",
    "    # Creating sparse representation to feed the placeholder\n",
    "    train_targets = sparse_tuple_from([targets])\n",
    "\n",
    "    return train_targets, original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nwp8s_TqnPNi"
   },
   "outputs": [],
   "source": [
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n] * len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1] + 1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qpqcBM_PnPQ0"
   },
   "outputs": [],
   "source": [
    "def sparse_tensor_to_strs(sparse_tensor):\n",
    "    indices= sparse_tensor[0][0]\n",
    "    values = sparse_tensor[0][1]\n",
    "    dense_shape = sparse_tensor[0][2]\n",
    "\n",
    "    strs = [ [] for i in range(dense_shape[0]) ]\n",
    "\n",
    "    string = []\n",
    "    ptr = 0\n",
    "    b = 0\n",
    "\n",
    "    for idx in range(len(indices)):\n",
    "        if indices[idx][0] != b:\n",
    "            strs[b] = string\n",
    "            string = []\n",
    "            b = indices[idx][0]\n",
    "\n",
    "        string.append(values[ptr])\n",
    "\n",
    "        ptr = ptr + 1\n",
    "\n",
    "    strs[b] = string\n",
    "\n",
    "    return strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "B0teJX71nXrv"
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, maxlen=None, dtype=np.float32,\n",
    "                  padding='post', truncating='post', value=0.):\n",
    "    lengths = np.asarray([len(s) for s in sequences], dtype=np.int64)\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # empty list was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wvxixd9wncfT"
   },
   "outputs": [],
   "source": [
    "def levenshtein(a,b):\n",
    "    \"Computes the Levenshtein distance between a and b.\"\n",
    "    n, m = len(a), len(b)\n",
    "\n",
    "    if n > m:\n",
    "        a,b = b,a\n",
    "        n,m = m,n\n",
    "\n",
    "    current = range(n+1)\n",
    "    for i in range(1,m+1):\n",
    "        previous, current = current, [i]+[0]*n\n",
    "        for j in range(1,n+1):\n",
    "            add, delete = previous[j]+1, current[j-1]+1\n",
    "            change = previous[j-1]\n",
    "            if a[j-1] != b[i-1]:\n",
    "                change = change + 1\n",
    "            current[j] = min(add, delete, change)\n",
    "\n",
    "    return current[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SlG18RAnnfmf"
   },
   "outputs": [],
   "source": [
    "def edit_distance(a,b,EOS=-1,PAD=-1):\n",
    "    _a = [s for s in a if s != EOS and s != PAD]\n",
    "    _b = [s for s in b if s != EOS and s != PAD]\n",
    "\n",
    "    return levenshtein(_a,_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8WvpjiKd2us3"
   },
   "outputs": [],
   "source": [
    "class CTC_PriMuS:\n",
    "    gt_element_separator = '-'\n",
    "    PAD_COLUMN = 0\n",
    "    validation_dict = None\n",
    "\n",
    "\n",
    "    def __init__(self, corpus_dirpath, corpus_filepath, dictionary_path, semantic, val_split = 0.0):\n",
    "        self.semantic = semantic\n",
    "        self.corpus_dirpath = corpus_dirpath\n",
    "\n",
    "        # Corpus\n",
    "        corpus_file = open(corpus_filepath,'r')\n",
    "        corpus_list = corpus_file.read().splitlines()\n",
    "        corpus_file.close()\n",
    "\n",
    "        self.current_idx = 0\n",
    "\n",
    "        # Dictionary\n",
    "        self.word2int = {}\n",
    "        self.int2word = {}\n",
    "            \n",
    "        dict_file = open(dictionary_path,'r')\n",
    "        dict_list = dict_file.read().splitlines()\n",
    "        for word in dict_list:\n",
    "            if not word in self.word2int:\n",
    "                word_idx = len(self.word2int)\n",
    "                self.word2int[word] = word_idx\n",
    "                self.int2word[word_idx] = word\n",
    "\n",
    "        dict_file.close()\n",
    "\n",
    "        self.vocabulary_size = len(self.word2int)\n",
    "        \n",
    "        \n",
    "        # Train and validation split\n",
    "        random.shuffle(corpus_list) \n",
    "        val_idx = int(len(corpus_list) * val_split) \n",
    "        self.training_list = corpus_list[val_idx:]\n",
    "        self.validation_list = corpus_list[:val_idx]\n",
    "        \n",
    "        print ('Training with ' + str(len(self.training_list)) + ' and validating with ' + str(len(self.validation_list)))\n",
    "\n",
    "    def nextBatch(self, params):\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        # Read files\n",
    "        for _ in range(params['batch_size']):\n",
    "            sample_filepath = self.training_list[self.current_idx]\n",
    "            sample_fullpath = self.corpus_dirpath + '/' + sample_filepath + '/' + sample_filepath\n",
    "            \n",
    "            # IMAGE\n",
    "            sample_img = cv2.imread(sample_fullpath + '.png', False)  # Grayscale is assumed!\n",
    "            height = params['img_height']\n",
    "            sample_img = resize(sample_img,height)\n",
    "            images.append(normalize(sample_img))\n",
    "\n",
    "            # GROUND TRUTH\n",
    "            if self.semantic:\n",
    "                sample_full_filepath = sample_fullpath + '.semantic'\n",
    "            else:\n",
    "                sample_full_filepath = sample_fullpath + '.agnostic'\n",
    "            \n",
    "            sample_gt_file = open(sample_full_filepath, 'r')\n",
    "            sample_gt_plain = sample_gt_file.readline().rstrip().split(word_separator())\n",
    "            sample_gt_file.close()\n",
    "\n",
    "            labels.append([self.word2int[lab] for lab in sample_gt_plain])\n",
    "\n",
    "            self.current_idx = (self.current_idx + 1) % len( self.training_list )\n",
    "\n",
    "\n",
    "        # Transform to batch\n",
    "        image_widths = [img.shape[1] for img in images]\n",
    "        max_image_width = max(image_widths)\n",
    "\n",
    "        batch_images = np.ones(shape=[params['batch_size'],\n",
    "                                       params['img_height'],\n",
    "                                       max_image_width,\n",
    "                                       params['img_channels']], dtype=np.float32)*self.PAD_COLUMN\n",
    "\n",
    "        for i, img in enumerate(images):\n",
    "            batch_images[i, 0:img.shape[0], 0:img.shape[1], 0] = img\n",
    "\n",
    "        # LENGTH\n",
    "        width_reduction = 1\n",
    "        for i in range(params['conv_blocks']):\n",
    "            width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "\n",
    "        lengths = [ batch_images.shape[2] / width_reduction ] * batch_images.shape[0]\n",
    "\n",
    "        return {\n",
    "            'inputs': batch_images,\n",
    "            'seq_lengths': np.asarray(lengths),\n",
    "            'targets': labels,\n",
    "        }\n",
    "        \n",
    "    def getValidation(self, params):\n",
    "        if self.validation_dict == None:                \n",
    "            images = []\n",
    "            labels = []\n",
    "    \n",
    "            # Read files\n",
    "            for sample_filepath in self.validation_list:\n",
    "                sample_fullpath = self.corpus_dirpath + '/' + sample_filepath + '/' + sample_filepath\n",
    "    \n",
    "                # IMAGE\n",
    "                sample_img = cv2.imread(sample_fullpath + '.png', False)  # Grayscale is assumed!\n",
    "                height = params['img_height']\n",
    "                sample_img = resize(sample_img,height)\n",
    "                images.append(normalize(sample_img))\n",
    "    \n",
    "                # GROUND TRUTH\n",
    "                if self.semantic:\n",
    "                    sample_full_filepath = sample_fullpath + '.semantic'\n",
    "                else:\n",
    "                    sample_full_filepath = sample_fullpath + '.agnostic'\n",
    "                \n",
    "                sample_gt_file = open(sample_full_filepath, 'r')\n",
    "            \n",
    "                sample_gt_plain = sample_gt_file.readline().rstrip().split(word_separator())\n",
    "                sample_gt_file.close()\n",
    "    \n",
    "                labels.append([self.word2int[lab] for lab in sample_gt_plain])\n",
    "    \n",
    "            # Transform to batch\n",
    "            image_widths = [img.shape[1] for img in images]\n",
    "            max_image_width = max(image_widths)\n",
    "    \n",
    "            batch_images = np.ones(shape=[len(self.validation_list),\n",
    "                                           params['img_height'],\n",
    "                                           max_image_width,\n",
    "                                           params['img_channels']], dtype=np.float32)*self.PAD_COLUMN\n",
    "    \n",
    "            for i, img in enumerate(images):\n",
    "                batch_images[i, 0:img.shape[0], 0:img.shape[1], 0] = img\n",
    "    \n",
    "            # LENGTH\n",
    "            width_reduction = 1\n",
    "            for i in range(params['conv_blocks']):\n",
    "                width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "    \n",
    "            lengths = [ batch_images.shape[2] / width_reduction ] * batch_images.shape[0]\n",
    "    \n",
    "            self.validation_dict = {\n",
    "                'inputs': batch_images,\n",
    "                'seq_lengths': np.asarray(lengths),\n",
    "                'targets': labels,\n",
    "            }\n",
    "            \n",
    "        \n",
    "        return self.validation_dict, len(self.validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HIDmJj5P2T1R"
   },
   "outputs": [],
   "source": [
    "def leaky_relu(features, alpha=0.2, name=None):\n",
    "  with ops.name_scope(name, \"LeakyRelu\", [features, alpha]):\n",
    "    features = ops.convert_to_tensor(features, name=\"features\")\n",
    "    alpha = ops.convert_to_tensor(alpha, name=\"alpha\")\n",
    "    return math_ops.maximum(alpha * features, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ddciVGGO2V24"
   },
   "outputs": [],
   "source": [
    "# params[\"height\"] = height of the input image\n",
    "# params[\"width\"] = width of the input image\n",
    "\n",
    "def default_model_params(img_height, vocabulary_size):\n",
    "    params = dict()\n",
    "    params['img_height'] = img_height\n",
    "    params['img_width'] = None\n",
    "    params['batch_size'] = 16\n",
    "    params['img_channels'] = 1\n",
    "    params['conv_blocks'] = 4\n",
    "    params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "    params['conv_filter_size'] = [ [3,3], [3,3], [3,3], [3,3] ]\n",
    "    params['conv_pooling_size'] = [ [2,2], [2,2], [2,2], [2,2] ]\n",
    "    params['rnn_units'] = 512\n",
    "    params['rnn_layers'] = 2\n",
    "    params['vocabulary_size'] = vocabulary_size\n",
    "    return params\n",
    "\n",
    "\n",
    "def ctc_crnn(params):\n",
    "    # TODO Assert parameters\n",
    "\n",
    "    input = tf.placeholder(shape=(None,\n",
    "                                   params['img_height'],\n",
    "                                   params['img_width'],\n",
    "                                   params['img_channels']),  # [batch, height, width, channels]\n",
    "                            dtype=tf.float32,\n",
    "                            name='model_input')\n",
    "\n",
    "    input_shape = tf.shape(input)\n",
    "\n",
    "    width_reduction = 1\n",
    "    height_reduction = 1\n",
    "\n",
    "\n",
    "    # Convolutional blocks\n",
    "    x = input\n",
    "    for i in range(params['conv_blocks']):\n",
    "\n",
    "        x = tf.layers.conv2d(\n",
    "            inputs=x,\n",
    "            filters=params['conv_filter_n'][i],\n",
    "            kernel_size=params['conv_filter_size'][i],\n",
    "            padding=\"same\",\n",
    "            activation=None)\n",
    "\n",
    "        x = tf.layers.batch_normalization(x)\n",
    "        x = leaky_relu(x)\n",
    "\n",
    "        x = tf.layers.max_pooling2d(inputs=x,\n",
    "                                    pool_size=params['conv_pooling_size'][i],\n",
    "                                    strides=params['conv_pooling_size'][i])\n",
    "\n",
    "        width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "        height_reduction = height_reduction * params['conv_pooling_size'][i][0]\n",
    "\n",
    "\n",
    "    # Prepare output of conv block for recurrent blocks\n",
    "    features = tf.transpose(x, perm=[2, 0, 3, 1])  # -> [width, batch, height, channels] (time_major=True)\n",
    "    feature_dim = params['conv_filter_n'][-1] * (params['img_height'] / height_reduction)\n",
    "    feature_width = input_shape[2] / width_reduction\n",
    "    features = tf.reshape(features, tf.stack([tf.cast(feature_width,'int32'), input_shape[0], tf.cast(feature_dim,'int32')]))  # -> [width, batch, features]\n",
    "\n",
    "    tf.constant(params['img_height'],name='input_height')\n",
    "    tf.constant(width_reduction,name='width_reduction')\n",
    "\n",
    "    # Recurrent block\n",
    "    rnn_keep_prob = tf.placeholder(dtype=tf.float32, name=\"keep_prob\")\n",
    "    rnn_hidden_units = params['rnn_units']\n",
    "    rnn_hidden_layers = params['rnn_layers']\n",
    "\n",
    "    rnn_outputs, _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "        tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(rnn_hidden_units), input_keep_prob=rnn_keep_prob)\n",
    "             for _ in range(rnn_hidden_layers)]),\n",
    "        tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(rnn_hidden_units), input_keep_prob=rnn_keep_prob)\n",
    "             for _ in range(rnn_hidden_layers)]),\n",
    "        features,\n",
    "        dtype=tf.float32,\n",
    "        time_major=True,\n",
    "    )\n",
    "\n",
    "    rnn_outputs = tf.concat(rnn_outputs, 2)\n",
    "\n",
    "    logits = tf.layers.dense(\n",
    "        rnn_outputs,\n",
    "        params['vocabulary_size'] + 1,  # BLANK\n",
    "        #activation_fn=None,\n",
    "    )\n",
    "    \n",
    "    tf.add_to_collection(\"logits\",logits) # for restoring purposes\n",
    "\n",
    "    # CTC Loss computation\n",
    "    seq_len = tf.placeholder(tf.int32, [None], name='seq_lengths')\n",
    "    targets = tf.sparse_placeholder(dtype=tf.int32, name='target')\n",
    "    ctc_loss = tf.nn.ctc_loss(labels=targets, inputs=logits, sequence_length=seq_len, time_major=True)\n",
    "    loss = tf.reduce_mean(ctc_loss)\n",
    "\n",
    "    # CTC decoding\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "    # decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits,seq_len,beam_width=50,top_paths=1,merge_repeated=True)\n",
    "\n",
    "    return input, seq_len, targets, decoded, loss, rnn_keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pX1GHytc3AHr"
   },
   "outputs": [],
   "source": [
    "#Train model\n",
    "\n",
    "corpus = 'Data/Package' #Path to the corpus\n",
    "set_path = 'Data/small_train.txt' #Path to the set file\n",
    "save_model = 'trained_semantic_model' #Path to save the model\n",
    "vocabulary = 'Data/vocabulary_semantic.txt' #Path to the vocabulary file\n",
    "semantic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1638695152801,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "iqaM4QMrAO-q",
    "outputId": "d1b796a1-7d3d-4347-cf03-a80fc9c0e6b9"
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "executionInfo": {
     "elapsed": 122924,
     "status": "error",
     "timestamp": 1638695276868,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "zbr84NC-2zrQ",
    "outputId": "29d46266-bd1a-46a3-e4d9-01197e79d154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 5516 and validating with 612\n",
      "Loss value at epoch 0:724.2706\n",
      "Validating...\n",
      "[Epoch 0] 24.308823529411764 (100.0 SER) from 612 samples.\n",
      "Saving the model...\n",
      "INFO:tensorflow:trained_semantic_model-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6908/3308934068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprimus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnextBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     _, loss_value = sess.run([train_opt, loss],\n\u001b[0m\u001b[0;32m     25\u001b[0m                              feed_dict={\n\u001b[0;32m     26\u001b[0m                                 \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inputs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1359\u001b[0m                            run_metadata)\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1439\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1440\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1441\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load primus\n",
    "\n",
    "primus = CTC_PriMuS(corpus, set_path, vocabulary, semantic, val_split = 0.1)\n",
    "\n",
    "# Parameterization\n",
    "img_height = 128\n",
    "params = default_model_params(img_height,primus.vocabulary_size)\n",
    "max_epochs = 64000\n",
    "dropout = 0.5\n",
    "\n",
    "# Model\n",
    "inputs, seq_len, targets, decoded, loss, rnn_keep_prob = ctc_crnn(params)\n",
    "train_opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(max_epochs):\n",
    "    batch = primus.nextBatch(params)\n",
    "\n",
    "    _, loss_value = sess.run([train_opt, loss],\n",
    "                             feed_dict={\n",
    "                                inputs: batch['inputs'],\n",
    "                                seq_len: batch['seq_lengths'],\n",
    "                                targets: sparse_tuple_from(batch['targets']),\n",
    "                                rnn_keep_prob: dropout,\n",
    "                            })\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        # VALIDATION\n",
    "        print ('Loss value at epoch ' + str(epoch) + ':' + str(loss_value))\n",
    "        print ('Validating...')\n",
    "\n",
    "        validation_batch, validation_size = primus.getValidation(params)\n",
    "        \n",
    "        val_idx = 0\n",
    "        \n",
    "        val_ed = 0\n",
    "        val_len = 0\n",
    "        val_count = 0\n",
    "            \n",
    "        while val_idx < validation_size:\n",
    "            mini_batch_feed_dict = {\n",
    "                inputs: validation_batch['inputs'][val_idx:val_idx+params['batch_size']],\n",
    "                seq_len: validation_batch['seq_lengths'][val_idx:val_idx+params['batch_size']],\n",
    "                rnn_keep_prob: 1.0            \n",
    "            }            \n",
    "                        \n",
    "            \n",
    "            prediction = sess.run(decoded,\n",
    "                                  mini_batch_feed_dict)\n",
    "    \n",
    "            str_predictions = sparse_tensor_to_strs(prediction)\n",
    "    \n",
    "\n",
    "            for i in range(len(str_predictions)):\n",
    "                ed = edit_distance(str_predictions[i], validation_batch['targets'][val_idx+i])\n",
    "                val_ed = val_ed + ed\n",
    "                val_len = val_len + len(validation_batch['targets'][val_idx+i])\n",
    "                val_count = val_count + 1\n",
    "                \n",
    "            val_idx = val_idx + params['batch_size']\n",
    "    \n",
    "        print ('[Epoch ' + str(epoch) + '] ' + str(1. * val_ed / val_count) + ' (' + str(100. * val_ed / val_len) + ' SER) from ' + str(val_count) + ' samples.')        \n",
    "        print ('Saving the model...')\n",
    "        saver.save(sess,save_model,global_step=epoch)\n",
    "        print ('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9ztUr5a4O5B"
   },
   "outputs": [],
   "source": [
    "#Decode a music score image with a trained model (CTC)\n",
    "\n",
    "img = 'Data/Package/000102695-1_1_1/000102695-1_1_1.jpg' #Path to the input image\n",
    "model = 'trained_semantic_model' #Path to the trained model\n",
    "vocab = 'Data/vocabulary_semantic.txt' #Path to the vocabulary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjSmbla84sWc"
   },
   "outputs": [],
   "source": [
    "# Read the dictionary\n",
    "dict_file = open(vocab,'r')\n",
    "dict_list = dict_file.read().splitlines()\n",
    "int2word = dict()\n",
    "\n",
    "for word in dict_list:\n",
    "    word_idx = len(int2word)\n",
    "    int2word[word_idx] = word\n",
    "dict_file.close()\n",
    "\n",
    "# Restore weights\n",
    "saver = tf.train.import_meta_graph(model)\n",
    "saver.restore(sess,args.model[:-5])\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "input = graph.get_tensor_by_name(\"model_input:0\")\n",
    "seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")\n",
    "rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "height_tensor = graph.get_tensor_by_name(\"input_height:0\")\n",
    "width_reduction_tensor = graph.get_tensor_by_name(\"width_reduction:0\")\n",
    "logits = tf.get_collection(\"logits\")[0]\n",
    "\n",
    "# Constants that are saved inside the model itself\n",
    "WIDTH_REDUCTION, HEIGHT = sess.run([width_reduction_tensor, height_tensor])\n",
    "\n",
    "decoded, _ = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "image = cv2.imread(args.image,False)\n",
    "image = resize(image, HEIGHT)\n",
    "image = normalize(image)\n",
    "image = np.asarray(image).reshape(1,image.shape[0],image.shape[1],1)\n",
    "\n",
    "seq_lengths = [ image.shape[2] / WIDTH_REDUCTION ]\n",
    "\n",
    "prediction = sess.run(decoded,\n",
    "                      feed_dict={\n",
    "                          input: image,\n",
    "                          seq_len: seq_lengths,\n",
    "                          rnn_keep_prob: 1.0,\n",
    "                      })\n",
    "\n",
    "str_predictions = sparse_tensor_to_strs(prediction)\n",
    "for w in str_predictions[0]:\n",
    "    print (int2word[w]),\n",
    "    print ('\\t'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1638721964314,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "t5WUmbE-j78Y",
    "outputId": "11a98f2e-780f-42a1-dd72-0a8a9af28cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'000051656-1_1_1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_file = open(\"Data/package_list.txt\", \"r\")\n",
    "packages = dir_file.readlines()\n",
    "dir_file.close()\n",
    "\n",
    "packages = [x.strip('\\n') for x in packages]\n",
    "\n",
    "print(len(packages))\n",
    "packages[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1638709833120,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "GQJgiAraeSRM",
    "outputId": "399aa840-1609-4cca-e461-7a9df471b576"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\nfor i in range(0, 8):\\n    print(i)\\n    for package in packages[i*10000: (i+1)*10000]:\\n        for parent, dirnames, filenames in os.walk('Data/Package/' + package):\\n            if len(filenames) != 6:\\n                print(package)\\n            break\\n\\nfor package in packages[80000:]:\\n    for parent, dirnames, filenames in os.walk('Data/Package/' + package):\\n        if len(filenames) != 6:\\n            print(package)\\n        break\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(0, 8):\n",
    "    print(i)\n",
    "    for package in packages[i*10000: (i+1)*10000]:\n",
    "        for parent, dirnames, filenames in os.walk('Data/Package/' + package):\n",
    "            if len(filenames) != 6:\n",
    "                print(package)\n",
    "            break\n",
    "\n",
    "for package in packages[80000:]:\n",
    "    for parent, dirnames, filenames in os.walk('Data/Package/' + package):\n",
    "        if len(filenames) != 6:\n",
    "            print(package)\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1638721964745,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "HSWTa0V5O4_g"
   },
   "outputs": [],
   "source": [
    "gt_element_separator = '-'\n",
    "\n",
    "saved_model = 'trained_semantic_model' #Path to save the model\n",
    "\n",
    "semantic = True\n",
    "corpus_dirpath = 'Data/Package'\n",
    "\n",
    "val_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1638721966876,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "0J_iY4X6PRfg",
    "outputId": "02798570-b56d-4ed1-ff04-4591b8f6f5ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_idx = 0\n",
    "\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "        \n",
    "dict_file = open('Data/vocabulary_semantic.txt','r')\n",
    "dict_list = dict_file.read().splitlines()\n",
    "\n",
    "for word in dict_list:\n",
    "    if not word in word2int:\n",
    "        word_idx = len(word2int)\n",
    "        word2int[word] = word_idx\n",
    "        int2word[word_idx] = word\n",
    "\n",
    "dict_file.close()\n",
    "vocabulary_size = len(word2int)\n",
    "\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1638721966429,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "uc41oV5ZPHX0",
    "outputId": "6ed49e6d-8e2a-47b8-b32b-65572606e8a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6128"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file = open('Data/small_train.txt','r')\n",
    "corpus_list = corpus_file.read().splitlines()\n",
    "corpus_file.close()\n",
    "\n",
    "len(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1638721966877,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "zCz4I37JPhOt",
    "outputId": "3de7f32f-0a03-40a3-a034-3f32b29a56b5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6908/3077546220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train and validation split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mval_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mval_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtraining_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalidation_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Train and validation split\n",
    "random.shuffle(corpus_list) \n",
    "val_idx = int(len(corpus_list) * val_split) \n",
    "training_list = corpus_list[val_idx:]\n",
    "validation_list = corpus_list[:val_idx]\n",
    "\n",
    "print ('Training with ' + str(len(training_list)) + ' and validating with ' + str(len(validation_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1638722270235,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "3aJjIc2LTBgs",
    "outputId": "9b759c45-d544-4dff-bb22-0d70977ef55f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/Package/000102695-1_1_1/000102695-1_1_1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_filepath = '000102695-1_1_1'\n",
    "#sample_filepath = training_list[1]\n",
    "sample_fullpath = corpus_dirpath + '/' + sample_filepath + '/' + sample_filepath\n",
    "\n",
    "sample_fullpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ti_b5NBRTUfJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22107de62e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img = cv2.imread(sample_fullpath + '.png', False)\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1638722090278,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "XabyGAqFVHDQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22107ed18b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "height = 128\n",
    "sample_img = resize(sample_img,height)\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1638722090279,
     "user": {
      "displayName": "Duy Vũ",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjrf609hqXDeY6VI54oD0nGYddWk4WfjXKyAq5USw=s64",
      "userId": "06384662092563932704"
     },
     "user_tz": -420
    },
    "id": "Drgh1kbIP65m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': array([[[[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.24313726],\n",
       "          ...,\n",
       "          [0.49411765],\n",
       "          [0.34509805],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.24313726],\n",
       "          [0.5294118 ],\n",
       "          ...,\n",
       "          [0.70980394],\n",
       "          [0.6       ],\n",
       "          [0.34901962]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]],\n",
       " \n",
       "         [[0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          ...,\n",
       "          [0.        ],\n",
       "          [0.        ],\n",
       "          [0.        ]]]], dtype=float32),\n",
       " 'seq_lengths': array([107.5, 107.5, 107.5, 107.5, 107.5, 107.5, 107.5, 107.5, 107.5,\n",
       "        107.5, 107.5, 107.5, 107.5, 107.5, 107.5, 107.5]),\n",
       " 'targets': [[10,\n",
       "   231,\n",
       "   1780,\n",
       "   823,\n",
       "   426,\n",
       "   692,\n",
       "   823,\n",
       "   1018,\n",
       "   823,\n",
       "   1717,\n",
       "   678,\n",
       "   1717,\n",
       "   0,\n",
       "   402,\n",
       "   1435,\n",
       "   1625,\n",
       "   402,\n",
       "   678,\n",
       "   402,\n",
       "   1717,\n",
       "   1599,\n",
       "   1717,\n",
       "   0],\n",
       "  [2,\n",
       "   231,\n",
       "   1780,\n",
       "   971,\n",
       "   1444,\n",
       "   1444,\n",
       "   1203,\n",
       "   1637,\n",
       "   1444,\n",
       "   1179,\n",
       "   1412,\n",
       "   408,\n",
       "   1412,\n",
       "   1606,\n",
       "   408,\n",
       "   1412],\n",
       "  [10, 1779, 877, 1470, 1663, 448, 1663, 0, 1470, 1225, 1027],\n",
       "  [7,\n",
       "   223,\n",
       "   1751,\n",
       "   245,\n",
       "   0,\n",
       "   1371,\n",
       "   1387,\n",
       "   1370,\n",
       "   1370,\n",
       "   0,\n",
       "   1370,\n",
       "   1559,\n",
       "   1370,\n",
       "   655,\n",
       "   0,\n",
       "   663,\n",
       "   663,\n",
       "   0],\n",
       "  [3, 1780, 809, 781, 983, 1180, 1188, 1179, 1179, 1179, 1008, 781, 556],\n",
       "  [10,\n",
       "   1769,\n",
       "   1599,\n",
       "   0,\n",
       "   1617,\n",
       "   823,\n",
       "   823,\n",
       "   583,\n",
       "   823,\n",
       "   0,\n",
       "   1018,\n",
       "   823,\n",
       "   1018,\n",
       "   1210,\n",
       "   1646,\n",
       "   1210,\n",
       "   0,\n",
       "   1617,\n",
       "   823,\n",
       "   823,\n",
       "   583,\n",
       "   823,\n",
       "   0,\n",
       "   1018,\n",
       "   1210,\n",
       "   1018,\n",
       "   823,\n",
       "   583,\n",
       "   402,\n",
       "   0],\n",
       "  [1,\n",
       "   222,\n",
       "   1757,\n",
       "   272,\n",
       "   0,\n",
       "   1727,\n",
       "   1727,\n",
       "   1188,\n",
       "   0,\n",
       "   402,\n",
       "   426,\n",
       "   1623,\n",
       "   402,\n",
       "   583,\n",
       "   820,\n",
       "   402,\n",
       "   0,\n",
       "   1225],\n",
       "  [10,\n",
       "   1779,\n",
       "   844,\n",
       "   824,\n",
       "   853,\n",
       "   844,\n",
       "   844,\n",
       "   0,\n",
       "   844,\n",
       "   1717,\n",
       "   1733,\n",
       "   1625,\n",
       "   403,\n",
       "   604,\n",
       "   824,\n",
       "   1044,\n",
       "   0,\n",
       "   1225,\n",
       "   1211,\n",
       "   1232,\n",
       "   1225,\n",
       "   1225,\n",
       "   0,\n",
       "   1225],\n",
       "  [10,\n",
       "   231,\n",
       "   1757,\n",
       "   402,\n",
       "   1018,\n",
       "   1210,\n",
       "   0,\n",
       "   1471,\n",
       "   1018,\n",
       "   1210,\n",
       "   441,\n",
       "   0,\n",
       "   1671,\n",
       "   1479,\n",
       "   1232,\n",
       "   1479,\n",
       "   1018,\n",
       "   402,\n",
       "   1454,\n",
       "   1210,\n",
       "   0,\n",
       "   1018],\n",
       "  [1,\n",
       "   1779,\n",
       "   1727,\n",
       "   418,\n",
       "   1018,\n",
       "   1018,\n",
       "   1018,\n",
       "   820,\n",
       "   0,\n",
       "   1018,\n",
       "   1018,\n",
       "   1717,\n",
       "   426,\n",
       "   604,\n",
       "   844,\n",
       "   823,\n",
       "   1018,\n",
       "   0,\n",
       "   597],\n",
       "  [10,\n",
       "   231,\n",
       "   1751,\n",
       "   832,\n",
       "   1741,\n",
       "   0,\n",
       "   823,\n",
       "   1454,\n",
       "   1210,\n",
       "   1018,\n",
       "   0,\n",
       "   1018,\n",
       "   823,\n",
       "   844,\n",
       "   0,\n",
       "   823,\n",
       "   678,\n",
       "   402,\n",
       "   1599,\n",
       "   0,\n",
       "   1427],\n",
       "  [1,\n",
       "   1757,\n",
       "   1426,\n",
       "   0,\n",
       "   793,\n",
       "   1426,\n",
       "   1617,\n",
       "   0,\n",
       "   418,\n",
       "   1617,\n",
       "   1426,\n",
       "   0,\n",
       "   844,\n",
       "   844,\n",
       "   402,\n",
       "   402,\n",
       "   0,\n",
       "   687,\n",
       "   597,\n",
       "   844,\n",
       "   0,\n",
       "   1036],\n",
       "  [7, 231, 1751, 1354, 1354, 0, 1354, 754, 0, 754, 754, 0, 754, 1381, 0],\n",
       "  [10,\n",
       "   1759,\n",
       "   1646,\n",
       "   0,\n",
       "   873,\n",
       "   1671,\n",
       "   1232,\n",
       "   853,\n",
       "   0,\n",
       "   604,\n",
       "   1044,\n",
       "   1599,\n",
       "   1599,\n",
       "   0,\n",
       "   823,\n",
       "   1018,\n",
       "   1210,\n",
       "   0,\n",
       "   1672,\n",
       "   1484,\n",
       "   1018,\n",
       "   1646,\n",
       "   0],\n",
       "  [1,\n",
       "   223,\n",
       "   1759,\n",
       "   245,\n",
       "   0,\n",
       "   1454,\n",
       "   1019,\n",
       "   692,\n",
       "   0,\n",
       "   119,\n",
       "   823,\n",
       "   678,\n",
       "   402,\n",
       "   0,\n",
       "   678,\n",
       "   678,\n",
       "   1717,\n",
       "   0],\n",
       "  [3,\n",
       "   1779,\n",
       "   1617,\n",
       "   844,\n",
       "   604,\n",
       "   426,\n",
       "   1617,\n",
       "   1405,\n",
       "   0,\n",
       "   1194,\n",
       "   1435,\n",
       "   1599,\n",
       "   1000,\n",
       "   1194,\n",
       "   1405,\n",
       "   1175,\n",
       "   1000,\n",
       "   774,\n",
       "   402,\n",
       "   0,\n",
       "   402,\n",
       "   1402,\n",
       "   1617,\n",
       "   1599,\n",
       "   1174,\n",
       "   1426,\n",
       "   0,\n",
       "   1405,\n",
       "   976,\n",
       "   1290,\n",
       "   1174,\n",
       "   992,\n",
       "   1717,\n",
       "   0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_COLUMN = 0\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Read files\n",
    "for _ in range(16):\n",
    "    sample_filepath = training_list[current_idx]\n",
    "    sample_fullpath = corpus_dirpath + '/' + sample_filepath + '/' + sample_filepath\n",
    "\n",
    "    # IMAGE\n",
    "    sample_img = cv2.imread(sample_fullpath + '.png', False)  # Grayscale is assumed!\n",
    "\n",
    "    height = 128\n",
    "    sample_img = resize(sample_img,height)\n",
    "    images.append(normalize(sample_img))\n",
    "\n",
    "    # GROUND TRUTH\n",
    "    if semantic:\n",
    "        sample_full_filepath = sample_fullpath + '.semantic'\n",
    "    else:\n",
    "        sample_full_filepath = sample_fullpath + '.agnostic'\n",
    "    \n",
    "    sample_gt_file = open(sample_full_filepath, 'r')\n",
    "    sample_gt_plain = sample_gt_file.readline().rstrip().split(word_separator())\n",
    "    sample_gt_file.close()\n",
    "\n",
    "    labels.append([word2int[lab] for lab in sample_gt_plain])\n",
    "\n",
    "    current_idx = (current_idx + 1) % len(training_list)\n",
    "\n",
    "\n",
    "# Transform to batch\n",
    "image_widths = [img.shape[1] for img in images]\n",
    "max_image_width = max(image_widths)\n",
    "\n",
    "batch_images = np.ones(shape=[16,\n",
    "                                128,\n",
    "                                max_image_width,\n",
    "                                1], dtype=np.float32)*PAD_COLUMN\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    batch_images[i, 0:img.shape[0], 0:img.shape[1], 0] = img\n",
    "\n",
    "# LENGTH\n",
    "width_reduction = 1\n",
    "for i in range(4):\n",
    "    width_reduction = width_reduction *  2\n",
    "\n",
    "lengths = [ batch_images.shape[2] / width_reduction ] * batch_images.shape[0]\n",
    "\n",
    "{\n",
    "    'inputs': batch_images,\n",
    "    'seq_lengths': np.asarray(lengths),\n",
    "    'targets': labels,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHTLxOoGd3bW"
   },
   "outputs": [],
   "source": [
    "\n",
    "validation_dict = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def getValidation(self, params):\n",
    "    if self.validation_dict == None:                \n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        # Read files\n",
    "        for sample_filepath in self.validation_list:\n",
    "            sample_fullpath = self.corpus_dirpath + '/' + sample_filepath + '/' + sample_filepath\n",
    "\n",
    "            # IMAGE\n",
    "            sample_img = cv2.imread(sample_fullpath + '.png', False)  # Grayscale is assumed!\n",
    "            height = params['img_height']\n",
    "            sample_img = resize(sample_img,height)\n",
    "            images.append(normalize(sample_img))\n",
    "\n",
    "            # GROUND TRUTH\n",
    "            if self.semantic:\n",
    "                sample_full_filepath = sample_fullpath + '.semantic'\n",
    "            else:\n",
    "                sample_full_filepath = sample_fullpath + '.agnostic'\n",
    "            \n",
    "            sample_gt_file = open(sample_full_filepath, 'r')\n",
    "        \n",
    "            sample_gt_plain = sample_gt_file.readline().rstrip().split(word_separator())\n",
    "            sample_gt_file.close()\n",
    "\n",
    "            labels.append([self.word2int[lab] for lab in sample_gt_plain])\n",
    "\n",
    "        # Transform to batch\n",
    "        image_widths = [img.shape[1] for img in images]\n",
    "        max_image_width = max(image_widths)\n",
    "\n",
    "        batch_images = np.ones(shape=[len(self.validation_list),\n",
    "                                        params['img_height'],\n",
    "                                        max_image_width,\n",
    "                                        params['img_channels']], dtype=np.float32)*self.PAD_COLUMN\n",
    "\n",
    "        for i, img in enumerate(images):\n",
    "            batch_images[i, 0:img.shape[0], 0:img.shape[1], 0] = img\n",
    "\n",
    "        # LENGTH\n",
    "        width_reduction = 1\n",
    "        for i in range(params['conv_blocks']):\n",
    "            width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "\n",
    "        lengths = [ batch_images.shape[2] / width_reduction ] * batch_images.shape[0]\n",
    "\n",
    "        self.validation_dict = {\n",
    "            'inputs': batch_images,\n",
    "            'seq_lengths': np.asarray(lengths),\n",
    "            'targets': labels,\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return self.validation_dict, len(self.validation_list)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9f5lBnI3oeFhZMwYN0gxm",
   "collapsed_sections": [],
   "name": "Sample_code.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "bkai",
   "language": "python",
   "name": "bkai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
